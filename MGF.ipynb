{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42847c2f",
   "metadata": {},
   "source": [
    "# Moment Generating Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559c389",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    " - $n$th Moment (Castella): For each integer $n$, the **$n$th moment** of $X$ (or $F_{X}(x)$), $\\mu_{n}' = E[X^{n}]$.\n",
    "\n",
    " - $n$th Central Moment (Castella): The **$n$th central moment** of $X$, $\\mu_{n} = E[(X - \\mu)^{n}]$, where $\\mu = \\mu_{1}' = E[X]$\n",
    "\n",
    " - Variance (Castella): The **variance** of a random variable $X$ is its second central moment; $Var[X] = E[(X - E[X])^{2}]$.\n",
    "\n",
    " - Moment Generating Function (Castella): Let $X$ be a random variable with cdf $F_{X}$. The **moment generating function (MGF)** of $X$ or $F_{X}$, denoted by $M_{X}(t) = E[e^{tX}]$, provided that the expectation exists for $t$ in some neighborhood of $0$. That is, there is an $h > 0$ such that, for all $t \\in (-h, h)$, $E[e^{tX}]$ exists. If the expectation doesn't exist in a neighborhood around $0$, we say that the MGF does not exist.\n",
    "\n",
    "   - If $X$ is continuous, $M_{X}(t) = \\int_{-\\infty}^{\\infty} e^{tx} f_{X}(x) dx$. \n",
    "   - If $X$ is discrete, $M_{X}(t) = \\sum_{x} e^{tx} P(X=x)$.\n",
    "\n",
    " - Moment Generating Function (Guntuboyina): The **moment generating function (MGF)** of $X$ is defined as the function $M_{X}(t) = E[e^{tX}]$ for all $t \\in \\mathbb{R}$ for which $E[e^{tX}]<\\infty$. Notice that $M_{X}(0) =1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b60ded",
   "metadata": {},
   "source": [
    "### Theorems\n",
    "\n",
    " - Theorem (Castella): If $X$ has MGF $M_{X}(t)$, then $E[X^{n}] = M_{X}^{(n)}(0)$, where $M_{X}^{(n)} (0) = \\frac{d^{n}}{dt^{n}} M_{X}(t) |_{t=0}$. In other words, the $n$th moment is equal to the $n$th derivative of $M_{X}(t)$ evaluated at $t=0$.\n",
    "\n",
    "\n",
    " - Theorem (Castella): Let $F_{X}(x) = F_{Y}(y)$ be two CDFs all of whose moments exist. \n",
    "     - If $X$ and $Y$ have bounded support, then $F_{X}(u) = F_{Y}(u)$ for all $u$ iff $E[X^{r}] = E[Y^{r}]$ for all integers $r = 0, 1, 2, 3, ...$. \n",
    "     -  If the MGFs exist and $M_{X}(t) = M_{Y}(t)$ for all $t$ in some neighborhood of $0$, then $F_{X}(u) = F_{Y}(u)$ for all $u$.\n",
    "     \n",
    "     \n",
    " - Convergence of MGFs, Theorem (Castella): Suppose $\\{X_{i}, i=1,2,...\\}$ is a sequence of random variables, each with MGF $M_{X_{i}}(t)$. Furthermore, suppose that $lim_{i \\rightarrow \\infty} M_{X_{i}}(t) = M_{X}(t)$ for all $t$ in a neighborhood of $0$, and $M_{X}(t)$ is an MGF. Then there is a unique CDF $F_{X}$ whose moments are determined by $M_{X}(t)$ and, for all $x$ where $F_{X}(x)$ is continuous we have $\\lim_{i \\rightarrow \\infty} F_{X_{i}(x) = F_{X}(x)}$. That is, convergence for $|t| < h$, of MGFs to an MGF implies convergence of CDFs.\n",
    " \n",
    " - Theorem (Castella): For any constants $a$ and $b$, the MGF of the random variable $aX+b$ is given by $M_{aX + b}(t) = e^{bt} M_{X}(at)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4dce4",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce722a",
   "metadata": {},
   "source": [
    "#### Exercise 2.25 \n",
    "\n",
    "Suppose the pdf $f_{X}(x)$ of a random variable $X$ is an even function. Show that \n",
    "\n",
    "a. $X$ and $-X$ are identically distributed. \n",
    "\n",
    "Since $f_{X}(x)$ is an even function, then $f_{X}(x) = f_{X}(-x)$ for every $x$.\n",
    "\n",
    "Using COV:\n",
    "\n",
    "Consider $Y=-X$. Then $X = -Y$.\n",
    "\n",
    "$$f_{Y}(y) = f_{X}(-y) \\left|\\frac{d}{dY} (-Y) \\right| = f_{X}(y) *1 = f_{X}(y)$$\n",
    "\n",
    "b. $M_{X}(t)$ is symmetric about $0$.\n",
    "\n",
    "Using the fact that $X$ and $-X$ are identically distributed.\n",
    "\n",
    "$$M_{X}(-t) = E \\left[e^{-tX} \\right] = \\int_{\\text{all } x} e^{tx} f_{-X}(x) dx = \\int_{\\text{all } x} e^{tx} f_{X}(x) dx = E \\left[e^{tX} \\right] = M_{X}(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfaa15a",
   "metadata": {},
   "source": [
    "#### Exercise 2.30 (Castella)\n",
    "\n",
    "Find the MGF corresponding to:\n",
    "\n",
    "a) $f(x) = \\frac{1}{c} ; 0 < x < c$\n",
    "\n",
    "\n",
    "$$E[e^{tX}] = \\int_{0}^{c} e^{tx} \\frac{1}{c}dx = \\frac{1}{c} \\frac{1}{t} e^{tx} \\bigg|_{0}^{c} = \\frac{1}{ct} \\left[e^{ct} - e^{0} \\right] = \\frac{e^{ct}-1}{ct}$$\n",
    "\n",
    "\n",
    "b) $f(x) = \\frac{2x}{c^{2}} ; 0 < x < c$\n",
    "\n",
    "$$E[e^{tX}]  = \\int_{0}^{c} e^{tx} \\frac{2x}{c^{2}}dx = \\frac{2}{c^{2}} \\int_{0}^{c} x e^{tx} dx$$\n",
    "\n",
    "\n",
    "Integrate by parts. Let $u = x$ ($du = dx$) and $dv = e^{tx}$ ($v =  \\frac{1}{t} e^{tx }$)\n",
    "\n",
    "$$=\\frac{2}{c^{2}}\\left[ \\left( \\frac{1}{t} x e^{tx}\\right)_{0}^{c} - \\frac{1}{t} \\int_{0}^{c}e^{tx} dx \\right] =\\frac{2}{c^{2}}\\left[ \\left(\\frac{c}{t} e^{tc} \\right) - \\left( \\frac{1}{t^2} e^{tx} \\right)_{0}^{c} dx \\right] = \\frac{2}{c^{2}} \\left[\\frac{c}{t}e^{tc} - \\left( \\frac{1}{t^{2}} e^{ct} - \\frac{1}{t^{2}} \\right) \\right] = \\frac{2}{c^{2} t^{2}} \\left[ ct e^{ct} - e^{ct} +1\\right]$$\n",
    "\n",
    "\n",
    "c) $f(x) = \\frac{1}{2\\beta} e^{-|x - \\alpha| / \\beta} ; -\\infty < x < \\infty; -\\infty < \\alpha < \\infty; \\beta > 0$\n",
    "\n",
    "\n",
    "$$E[e^{tX}]  = \\int_{-\\infty}^{\\infty} e^{tx} \\frac{1}{2\\beta} e^{-|x - \\alpha| / \\beta} dx = \\frac{1}{2\\beta}\\left[\\int_{\\alpha}^{\\infty} \\exp\\{tx\\} \\exp\\left\\{ -\\frac{x-\\alpha}{\\beta} \\right\\} + \\int_{-\\infty}^{\\alpha} \\exp\\{tx\\} \\exp\\left\\{ \\frac{x-\\alpha}{\\beta} \\right\\}\\right]$$\n",
    "\n",
    "$$= \\frac{1}{2\\beta}\\left[\\int_{\\alpha}^{\\infty} \\exp \\left\\{ -\\frac{x-\\alpha - t\\beta x}{\\beta} \\right\\} dx + \\int_{-\\infty}^{\\alpha} \\exp \\left\\{ \\frac{x-\\alpha + t\\beta x}{\\beta} \\right\\} dx\\right]$$\n",
    "\n",
    "$$= \\frac{1}{2\\beta}\\left[\\int_{\\alpha}^{\\infty} \\exp \\left\\{ -\\frac{x - t\\beta x}{\\beta} \\right\\} \\exp\\left\\{ \\frac{\\alpha}{\\beta} \\right\\} dx + \\int_{-\\infty}^{\\alpha} \\exp \\left\\{ \\frac{x + t\\beta x}{\\beta} \\right\\} \\exp\\left\\{ -\\frac{\\alpha}{\\beta} \\right\\}dx \\right]$$\n",
    "\n",
    "$$= \\frac{1}{2\\beta}\\left[\\int_{\\alpha}^{\\infty} \\exp \\left\\{ -\\frac{(1-t\\beta)x}{\\beta} \\right\\} \\exp\\left\\{ \\frac{\\alpha}{\\beta} \\right\\} dx + \\int_{-\\infty}^{\\alpha} \\exp \\left\\{ \\frac{(1+t\\beta)x}{\\beta} \\right\\} \\exp\\left\\{ -\\frac{\\alpha}{\\beta} \\right\\}dx \\right]$$\n",
    "\n",
    "$$=\\frac{1}{2\\beta} \\left[ -\\left[e^{\\alpha / \\beta} \\left(\\frac{\\beta}{t\\beta - 1 } \\right) e^{-\\frac{(1-t\\beta )x}{\\beta}} \\right]_{\\alpha}^{\\infty}+ \\left[e^{-\\alpha/\\beta} \\frac{\\beta}{1+t\\beta} e^{ \\frac{(1+t\\beta)x}{\\beta}} \\right]_{-\\infty}^{\\alpha} \\right]$$\n",
    "\n",
    "\n",
    "$$=\\frac{1}{2\\beta} \\left[ -e^{\\alpha / \\beta} \\left(\\frac{\\beta}{t\\beta - 1 } \\right) \\left[1- e^{-\\frac{(1-t\\beta)\\alpha}{\\beta}} \\right] + e^{-\\alpha / \\beta} \\left( \\frac{\\beta}{ 1+t\\beta} \\right) \\left[ e^{\\frac{(1+t\\beta)\\alpha}{\\beta}} -1 \\right] \\right]$$\n",
    "\n",
    "\n",
    "d) $P(X = x) = \\binom{r+x-1}{ x} p^{r}(1-p)^{x}; x = 0, 1, ....,  0 <p <1, r \\in \\mathbb{Z}$\n",
    "\n",
    "$$E\\left[t^{tX}\\right] = \\sum_{x=0}^{\\infty} e^{tx} \\binom{r+x-1}{ x} p^{r}(1-p)^{x} = \\frac{p^{r}}{(1- e^{t}(1-p))^{r}}\\sum_{x=0}^{\\infty} \\binom{r+x-1}{ x} (1- e^{t}(1-p))^{r} (e^t(1-p))^{x}$$\n",
    "\n",
    "If $e^{t}(1-p) < 1$:\n",
    "\n",
    "$$= \\frac{p^{r}}{(1- e^{t}(1-p))^{r}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1529fca",
   "metadata": {},
   "source": [
    "#### Exercise 2.31 (Castella)\n",
    "\n",
    "Does a distribution exist for which $M_{X}(t) = \\frac{t}{1-t}$, $|t| < 1$? If yes, find it. If no, prove it.\n",
    "\n",
    "By definition, $M_{X}(t) = E[e^{tX}]$, which when $t=0$ implies that $M_{X}(0)=1$ for any valid MGF.\n",
    "However, $\\frac{t}{1-t} \\bigg|_{t=0} = 0$. Thus, a distribution does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62704461",
   "metadata": {},
   "source": [
    "#### Exercise 2.33 (Castella)\n",
    "\n",
    "In each of the following cases, verify the expression given for the MGF, and in each case, use the MGF to evaluate $E(X)$ and $V(X)$. \n",
    "\n",
    "a) $P(X=x) = \\frac{e^{-\\lambda} \\lambda^{x}}{x!}$ and $M_{X}(t) = e^{\\lambda (e^{t}-1)}$, $x = 0, 1, ....$; $\\lambda > 0$\n",
    "\n",
    "\n",
    "$$E\\left[e^{tX} \\right] = \\sum_{x=0}^{\\infty} e^{tx} \\frac{e^{-\\lambda} \\lambda^{x}}{x!} = e^{-\\lambda} \\sum_{x=0}^{\\infty} \\frac{(e^{t} \\lambda)^{x}}{x!} =e^{-\\lambda} e^{e^{t}\\lambda} = e^{\\lambda (e^{t}-1)}$$\n",
    "\n",
    "\n",
    "Take the derivative with respect to $t$ and evaluate at $t=0$: $\\frac{d}{dt} e^{\\lambda (e^{t}-1)} \\bigg|_{t=0} = (\\lambda e^{t}) e^{\\lambda (e^{t}-1)} \\bigg|_{t=0}=\\lambda$\n",
    "\n",
    "Take the second derivative with respect to $t$ and evaluate at $t=0$: $\\frac{d}{dt} (\\lambda) e^{\\lambda e^{t}-\\lambda + t} \\bigg|_{t=0} = \\lambda e^{\\lambda e^{t} - \\lambda + t} (\\lambda e^{t} + 1) \\bigg|_{t=0} = \\lambda^{2} + \\lambda$\n",
    "\n",
    "\n",
    "$$E[X] = \\lambda$$\n",
    "\n",
    "\n",
    "$$V[X] = \\lambda^{2} + \\lambda - (\\lambda)^{2} = \\lambda$$\n",
    "\n",
    "\n",
    "b) $P(X=x) = p(1-p)^{x}$ and $M_{X}(t) = \\frac{p}{1-(1-p)e^{t}}$, $x = 0, 1, ....$; $0<p<1$\n",
    "\n",
    "\n",
    "$$E\\left[e^{tX} \\right] = \\sum_{x=0}^{\\infty} e^{tx} p (1-p)^{x} = \\sum_{x=0}^{\\infty} p (e^{t} (1- p) )^{x} = \\frac{p}{1-(e^{t} - p e^{t})} = \\frac{p}{1-(1-p)e^{t}}$$\n",
    "\n",
    "Take the derivative with respect to $t$ and evaluate at $t=0$: $\\frac{d}{dt}  \\frac{p}{1-(1-p)e^{t}} = -\\frac{p}{(1-(1-p)e^{t})^{2}} (e^{t}-pe^{t}) \\bigg|= \\frac{p (e^{t}-pe^{t}) }{(1-(1-p)e^{t})^{2}} \\bigg|_{t=0} = \\frac{p(1-p)} {p^{2}} = \\frac{1-p}{p}$\n",
    "\n",
    "\n",
    "\n",
    "c) $f_{X}(x) = \\frac{e^{-(x-\\mu)^{2} / (2 \\sigma^{2})}  }{\\sqrt{2\\pi} \\sigma}$ and $M_{X}(t) =  e^{\\mu t. + \\sigma^{2} t^{2} / 2}$, $-\\infty < x < \\infty$; $-\\infty < \\mu < \\infty$; $\\sigma > 0$\n",
    "\n",
    "\n",
    "$$E\\left[e^{tX} \\right] =\\int_{-\\infty}^{\\infty} e^{tx} \\frac{e^{-(x-\\mu)^{2} / (2 \\sigma^{2})}  }{\\sqrt{2\\pi} \\sigma}dx  = \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left \\{ \\frac{-(x^2-2\\mu x + \\mu^{2}) + tx 2\\sigma^{2}}{ 2\\sigma^{2}}  \\right\\}  \\exp \\left\\{ -\\mu t - \\sigma^{2} t^{2} / 2 \\right\\} dx$$\n",
    "$$= \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi} \\sigma}  \\exp\\left\\{ \\frac{-x^{2} + 2\\mu x - \\mu^{2} + 2t\\sigma^{2} x - 2\\sigma^{2} \\mu t - \\sigma^{4}t^{2} }{2\\sigma^{2}} \\right\\} dx$$\n",
    "$$ = \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi} \\sigma}  \\exp\\left\\{\\frac{ -x^{2} + 2(\\mu  + \\sigma^{2} t)x -(\\mu^{2} + 2\\mu t \\sigma^{2} + \\sigma^{4} t^{2}) }{2\\sigma^{2}}\\right\\} dx$$\n",
    "$$= \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi} \\sigma}  \\exp\\left\\{ -\\frac{(x-(\\mu \\sigma^{2} t))^{2}}{ 2 \\sigma^{2}} \\right\\} dx$$\n",
    "$$=\\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}$$\n",
    "\n",
    "Take the derivative with respect to $t$ and evaluate at $t=0$:\n",
    "\n",
    "$$\\frac{d}{dt} \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}\\bigg|_{t=0} = \\mu \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}\\bigg|_{t=0} = \\left[\\mu + 2\\sigma^{2} t / 2\\right] \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}  \\bigg|_{t=0} = \\mu$$\n",
    "\n",
    "$$\\frac{d}{dt}\\left[\\mu + 2\\sigma^{2} t / 2\\right] \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}  \\bigg|_{t=0} = \\left[ \\sigma^{2} \\right] \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}  + \\left[\\mu + 2\\sigma^{2} t / 2\\right]^{2} \\exp \\left\\{ \\mu t + \\sigma^{2} t^{2} / 2 \\right\\}\\bigg|_{t=0} = \\mu^{2} +  \\sigma^{2}$$\n",
    "\n",
    "$$E[X] = \\mu$$\n",
    "\n",
    "\n",
    "$$V[X] = \\mu^{2} +  \\sigma^{2} - [\\mu]^{2} = \\sigma^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfa863",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb749126",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5ec95b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d6dab3",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    " - \"Statistical Inference\" by Casella et al\n",
    " \n",
    " - http://pages.stat.wisc.edu/~shao/stat609/stat609-05.pdf\n",
    " \n",
    " - https://web.ma.utexas.edu/users/gordanz/notes/mgf_color.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee920fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
