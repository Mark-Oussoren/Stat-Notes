{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5834a3c1",
   "metadata": {},
   "source": [
    "# PAC Learning Framework\n",
    "\n",
    "In this section, I will concisely cover the Probably Approximately Correct (PAC) learning framework. \n",
    "\n",
    "## Motivation\n",
    "In a sentence, the PAC framework quantifies the requirements (number of training points, time complexity, and space complexity) to approximately learn patterns in the data. THIS IS HUGE! For instance, a simple example is learning linear versus nonlinear maps between the input and outputs - linear patterns intuitively require less points to learn the pattern. Concretely, we could look at predicting height with weight data. If we desired a linear pattern, then we only need to search over $\\mathbb{R}_+$ to find a parameter $\\alpha$ such that $\\text{height}=\\alpha\\cdot \\text{weight}$. If instead we desire a nonlinear pattern, then think about the expansion of the space! We could fit polynomials, trigonometric, and the list goes on. I believe this should provide sufficient motivation for why we care deeply about quantifying the number of samples we need depending on the relationships we deem important (linear, nonlinear, indicator functions, exponentials, etc.). Now, I turn to mathematics for precision and clarity.\n",
    "\n",
    "## Some Notations\n",
    "\n",
    "- Let $\\mathcal{X}$ denote the input space (includes all data excluding the output variable)\n",
    "\n",
    "- Let $\\mathcal{Y}$ denote the set of labels/output/target variables (as in [1], I limit discussion to binary outputs right now)\n",
    "\n",
    "- Examples $(x,y)\\in(\\mathcal{X},\\mathcal{Y})$ are assumed to be drawn independently and identically distributed (i.i.d.) according to some unknown distribution $\\mathcal{D}$ \n",
    "\n",
    "- \n",
    "\n",
    "## Definitions\n",
    "\n",
    "**Concept**: A concept $c:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is a mapping from $\\mathcal{X}$ to $\\mathcal{Y}$.\n",
    "\n",
    "**Concept Class**: A concept class $\\mathcal{C}$ is a set of concepts we may wish to learn.  \n",
    "\n",
    "## Examples\n",
    "\n",
    "- Let us consider the features to be height, weight, age, ethnicity, and cancer (boolean) with the target being death (boolean). Then let us discuss concepts: for instance, all instances of Germans over 6' with weight >300lbs with cancer and over the age 55 get mapped to 1 i.e. they're dead (this is made up). This concept is thus an indicator function. We could consider a concept class to be a union of similar indicator variables. This type of concept class forms the basis for rule-based algorithms which will be discussed in a separate notebook.\n",
    "\n",
    "- In the book, they discuss out of the ordinary examples - such as the concept class of triangles or circles or other geometric figures. While yes these are technically concept classes, they are sparsely used in practice.\n",
    "\n",
    "## Definitions\n",
    "\n",
    "**Generalization Error**: Given a hypothesis $h\\in\\mathcal{H}$, a target concept $c\\in\\mathcal{C}$, and an underlying distribution $D$, the generalization error or risk of $h$ is defined by \n",
    "\n",
    "$$R(h) = P_{x\\sim D}\\left[h(x)\\neq c(x)\\right] = \\mathbb{E}_{x\\sim D}\\left[\\mathbb{I}_{h(x)\\neq c(x)}\\right].$$\n",
    "\n",
    "In words, it is the probability that the hypothesis does not align with the target concept. This is of course unknown as we do not know $D$; however, we can measure the empirical error of the hypothesis based on a labeled sample of the data.\n",
    "\n",
    "**Empirical Error**: Given a hypothesis $h\\in\\mathcal{H}$, a target concept $c\\in\\mathcal{C}$, and a sample $S=(x_1,\\dots,x_m)$, the empirical error or risk of $h$ is defined by \n",
    "\n",
    "$$\\hat{R}(h) = \\frac{1}{m}\\sum\\limits_{i=1}^m \\mathbb{I}_{h(x_i)\\neq c(x_i)}.$$\n",
    "\n",
    "It is an emsemble of the error derived from the sample $S$.\n",
    "\n",
    "**PAC-learning**: A concept class $C$ is said to be PAC-learnable if there exists an algorithm $\\mathcal{A}$ and a polynomial function $poly(\\cdot,\\cdot,\\cdot,\\cdot)$ such that for any $\\epsilon>0$ and $\\delta>0$, for all distributions $D$ on $\\mathcal{X}$ and for any target concept $c\\in\\mathcal{C}$, the following holds for any sample size $m\\geq poly(\\epsilon^{-1},\\delta^{-1},n,size(c))$:\n",
    "\n",
    "$$\\mathbb{P}_{S\\sim D^m} \\left[R(h_S)\\leq \\epsilon\\right]\\geq 1-\\delta.$$ \n",
    "\n",
    "If $\\mathcal{A}$ further runs in $poly(\\epsilon^{-1},\\delta^{-1},n,size(c))$, then $C$ is said to be efficiently PAC-learnable. When such an algorithm $\\mathcal{A}$ exists, it is called a PAC-learning algorithm for $C$.\n",
    "\n",
    "*Note on PAC-learning*: This definition is CRAZY!! I can draw the samples from any distribution of my choosing - the exponetial, Cauchy, uniform, a crazy convolution of all three, etc. and it still holds that the generalization error of a hypothesis on the samples is bounded above by $\\epsilon$ with some high probability $1-\\delta$. The definition stattes that after enough samples (whose exact number is based on some polynomial of the error, bound, the dimension of the data, and the size of the concept representation). HOWEVER, the test data must be distributed according to the same as the training set - in other words, we impose a stationary condition that is all too common and all too unrealistic in practice. FURTHERMORE, we make a statement about the entire concept class - so we must cast quite a wide net to catch all the possible fish (target concepts). I wonder if this can be relaxed to just focus on a subset of a concept class...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d57547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe36bfb",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "[1] \"Foundations of Machine Learning\" by Mohri et al., 2012"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
