{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf99197",
   "metadata": {},
   "source": [
    "# Bayesian Statistics\n",
    "\n",
    "## Exposition\n",
    "\n",
    "I don't care for this stuff, but someone could fill in here about their passion for $\\alpha$ fishes and priors over frequentist views. I do like hierarchical models and the Gibbs Sampler, so I may add that later here.\n",
    "\n",
    "## Key Terms/Definitions:\n",
    "\n",
    "- Prior Distribution: $f(\\theta)$\n",
    "- Posterior Distribution: $f(\\theta|X)$\n",
    "- Conjugate Prior: if $f(\\theta)=f(\\theta|X)$, then the two are called conjugate distributions\n",
    "- Probability is measured in terms of confidence/entropy/certainty\n",
    "- Normalizing Constant: $\\int_\\Theta f(X|\\theta)f(\\theta)d\\theta$\n",
    "- $1-\\alpha$ Posterior Interval: Find the $(a,b):$ $P(\\Theta\\in (a,b)|X)=\\int\\limits_a^b f(\\theta|X)d\\theta=1-\\alpha$.\n",
    "\n",
    "- Baye's Theorem: $$P(X|Y)=\\frac{P(X\\cap Y)}{P(Y)}=\\frac{P(Y|X)P(X)}{P(Y)}$$\n",
    "- Let $B(a,b)$ denote the Beta function which equals $$\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}$$\n",
    "\n",
    "* The gamma function, $\\Gamma(\\alpha)$ is defined by $$\\Gamma(\\alpha)=\\int_0^\\infty x^{\\alpha - 1}e^{-x}dx$$\n",
    "\n",
    "## Finding Posterior Distributions\n",
    "\n",
    "**Example 1**: Let $X|\\Theta=\\theta\\sim\\mathcal{N}(\\mu,\\theta^2)$ be the likelihood and $\\Theta\\sim \\text{Rayleigh}(1)$. Let us calculate the prior $f(\\theta)$.\n",
    "\n",
    "* $$P(X=x)=\\int\\limits_\\Theta P(X=x|\\Theta=\\theta)P(\\Theta=\\theta)d\\theta$$\n",
    "\n",
    "$$=\\int\\limits_0^\\infty \\frac{1}{\\sqrt{2\\pi}\\theta} e^{\\frac{(x-\\mu)^2}{2\\theta^2}}\\times \\theta e^{-\\frac{\\theta^2}{2}}d\\theta=\\frac{1}{\\sqrt{2\\pi}}\\int\\limits_0^\\infty e^{-\\frac{1}{2}(\\theta^2-\\frac{1}{\\theta^2}(x-\\mu)^2)}\\;\\;\\;d\\theta$$\n",
    "\n",
    "From here, we complete the square to get  \n",
    "\n",
    "$$(\\theta^2-\\frac{(x-\\mu)^2}{\\theta^2})=(\\theta-\\frac{|x-\\mu|}{\\theta})^2-2|x-\\mu|$$\n",
    "\n",
    "which gives \n",
    "\n",
    "$$P(X=x)=\\frac{1}{\\sqrt{2\\pi}}e^{-|x-\\mu|}\\int_0^\\infty e^{-\\frac{1}{2}(\\theta-\\frac{|x-\\mu|}{\\theta})^2}d\\theta.$$\n",
    "\n",
    "Denote this last integral by $I$ and let $\\omega=-\\frac{|x-\\mu|}{\\theta}$ so $\\omega\\in(0,\\infty)$ and $d\\omega=\\frac{|x-\\mu|}{\\theta^2}d\\theta=\\frac{\\omega^2}{|x-\\mu|}d\\theta$ with $\\theta=-\\frac{|x-\\mu|}{\\omega}$. Then \n",
    "\n",
    "$$I=\\frac{1}{\\sqrt{2\\pi}}e^{-|x-\\mu|}\\int\\limits_0^\\infty e^{-\\frac{1}{2}(-\\frac{|x-\\mu|}{\\omega}+\\omega)^2}\\times\\frac{|x-\\mu|}{\\omega^2}d\\omega.$$\n",
    "\n",
    "As the integrands and integrals are equivalent, we know \n",
    "\n",
    "$$I+I=2I=\\frac{1}{\\sqrt{2\\pi}}e^{-|x-\\mu|}\\int\\limits_0^\\infty (1+\\frac{|x-\\mu|}{\\omega^2})e^{-\\frac{1}{2}(e^{-(\\frac{|x-\\mu|}{\\omega}+\\omega)})^2}d\\omega.$$\n",
    "\n",
    "Letting $z=\\omega-\\frac{|x-\\mu|}{\\omega}$ yields $dz=\\left(1+\\frac{|x-\\mu|}{\\omega^2}\\right)d\\omega$ so then \n",
    "\n",
    "$$2I=\\frac{1}{\\sqrt{2\\pi}}e^{-|x-\\mu|}\\int\\limits_0^\\infty e^{-z^2}dz=e^{-|x-\\mu|}\\iff P(X=x)=I=\\frac{1}{2}e^{-|x-\\mu|}$$\n",
    "\n",
    "which implies that $X$ is Laplace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36c00d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1f217f",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- \"A First Course in Bayesian Statistical Methods\" by Hoff\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
